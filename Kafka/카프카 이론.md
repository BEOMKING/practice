# Kafka
카프카란 오픈소스 분산 이벤트 스트리밍 플랫폼이다. 비동기 메시징을 처리하는 메시지 큐로 많이 사용된다.

발행/구독 모델(pub/sub)의 방식을 사용한다. 즉, 데이터를 전송하는 방식이 아닌 받기를 원하는 주체가 토픽(topic)을 구독함으로써 데이터를 읽어오는 방식이다.

## 구조

<img src="assets/structure.png" alt="img" style="zoom:80%;" />

- Broker
  
  카프카 클러스터는 여러 개의 브로커로 이루어져 있다. 이 브로커들이 각각의 서버라고 볼 수 있다. 이 브로커들이 메시지를 나눠서 저장, 이중화, 장애 발생시 대체 등을 수행한다.
  
- Zookeeper

  카프카 클러스터를 관리하는 역할을 한다. 카프카 클러스터와 관련된 정보가 기록이 되고 관리가 된다.

- Producer
  
  카프카 클러스터에 메시지를 발행(produce)하는 역할을 한다.
  
- Consumer

  카프카 클러스터에서 메시지를 읽는(consume) 역할을 한다.

## Topic & Partition

토픽은 메세지를 저장하는 단위를 의미한다. 

여러 가지 메시지가 있을 때 이 메시지들을 구분하기 위한 용도로 사용된다.

토픽은 한 개 이상의 파티션으로 구성된다. 즉, 파티션은 메시지를 저장하는 물리적인 파일을 의미한다.

- 파티션은 추가만 가능한(append only) 파일
- 각 메시지 저장 위치를 오프셋(offset)이라고 한다.
- 프로듀서가 넣은 메시지는 큐와 같이 파티션의 맨 뒤에 추가된다.
- 컨슈머는 오프셋 기준으로 메시지를 순서대로 읽는다.
- 메시지는 읽어진다고 삭제되지 않으며 설정에 따라 일정 시간이 지난 뒤에 삭제된다.

<img src="assets/topic-partition.png" alt="img" style="zoom:80%;" />

## Producer

카프카 클러스터에 메시지를 발행(produce)하는 역할을 한다.

라운드 로빈(round-robin) 또는 키를 이용해 저장할 파티션을 선택해서 저장한다.

키 방식의 경우, 프로듀서가 카프카에 메시지를 전송할 때 토픽뿐만 아니라 키를 지정할 수 있다. 이 때, 키의 해시값을 이용해 저장할 토픽을 선택한다. 같은 키에 대해서는 메시지 순서가 유지된다.

<img src="assets/producer-partitions.png" alt="img" style="zoom:60%;" />

#### 흐름

<img src="assets/producer-flow.png" alt="img" style="zoom:60%;" />

프로듀서 애플리케이션에서 send() 메소드를 통해 메시지를 보내면 직렬화 -> 파티션 결정 -> 메시지 배치 적재 -> Sender 순으로 전송된다.

Buffer에 메시지를 적해하는 쓰레드와 Sender로 메시지를 전송하는 쓰레드는 별도의 쓰레드다. 따라서 Sender가 보낼때 메시지가 적재하지 못한다던가 메시지가 적재될 때 Sender가 전송을 하지 못하는 문제는 발생하지 않는다.

#### 주요 속성

프로듀서와 관련된 주요 속성은 다음이 있다.

- batch.size

  배치 크기. 배치가 다 차면 전송한다.

  batch.size가 너무 작으면 한 번에 처리할 수 있는 데이터가 너무 적어지므로 처리량이 감소한다.

- linger.ms

  전송 대기 시간(기본값 O)

  linger.ms 설정으로 어느 정도 대기 시간을 가진 후에 배치를 처리하므로 한 번에 처리할 수 있는 메시지가 늘어 처리량이 증가한다.

- max.block.ms

  주요 속성은 아닌데 send()로 데이터를 전송할 때, buffer.memory 값을 초과하는 경우 딜레이가 발생한다.

  프로듀거사 브로커에 전송하는 속도보다 버퍼에 더 빠르게 쌓일 경우 max.block.ms 시간만큼 send() 요청을 블로킹한다.

#### 전송 결과 확인

전송 결과를 확인하는 방법은 3가지가 있다.

- 전송 결과를 확인하지 않음

  ```java
  producer.send(new ProducerRecord<>("key", "value"));
  ```

  전송 실패를 알 수 없으며 별도 처리가 필요 없는 메시지 전송에 사용한다.

- 전송 결과를 확인함 - Future

  ```jade
  Future<RecordMetadata> f = producer.send(new ProducerRecord<>("key", "value"));
  try {
  	RecordMetadata meta = f.get(); // 블로킹
  } catch (ExecutionException ex) {
  	// 처리
  }
  ```

  블로킹 방식을 사용하기 때문에 배치 효과가 떨어져 처리량이 저하된다.

- 전송 결과를 확인함 - Callback

  ```java
  producer.send(new ProducerRecord<>("key", "value")),
  	new Callback() {
  		@Override
  		public void onCompletion(RecordMetadata metadata, Exception ex) {
  			// 처리
  		}
  	});
  ```

  처리량 저하가 없는 논블로킹 방식

#### 전송 보장과 ack

- ack = 0

  - 서버 응답 대기 x
  - 전송 보장 0

- ack = 1

  - 파티션의 리더에 저장되면 응답을 받는다.
  - 리더가 받아 응답을 보내고 팔로워에 저장되지 않은 상태에서 리더에 장애가 생기면 데이터가 유실될 수 있다.

- ack = all (-1)

  - 모든 리플리카에 저장되면 응답을 받는다.

  - min.insync.replicas (브로커 옵션)

    프로듀서 ack 옵션이 all일 때 저장에 성공할 수 있다고 응답할 수 있는 동기화된 리플리카 최소 개수

    Ex. min.insync.replicas = 2이고 리플리카가 3개라면 리더, 팔로워 1개에 저장되면 정상 응답을 보낸다.

    ​	값을 1로 설정한것과 ack = 1로 설정한 것은 같은 것이다.

    > 값을 리플리카 개수와 똑같이 설정하면 안된다.
    >
    > 리플리카 중 한개라도 장애가 나면 항상 실패를 리턴하기 때문이다.

#### 에러 유형

- 전송 과정에서 실패
  - 전송 타임 아웃(일시적인 네트워크 오류 등)
  - 리더 다운에 의한 새 리더 선출 진행 중
  - 브로커 설정 메시지 크기 한도 초과 등
- 전송 전에 실패
  - 직렬화 실패, 프로듀서 자체 요청 크기 제한 초과
  - 프로듀서 버퍼가 차서 기다린 시간이 최대 대기 시간 초과 등

#### 실패 대응 1 : 재시도

- 재시도
  - 재시도 가능한 에러는 재시도 처리
    - 예: 브로커 응답 타임 아웃, 일시적인 리더 없음 등
- 재시도 위치
  - 프로듀서는 기본적으로 자체적으로 브로커 전송 과정에서 에러가 발생하면 재시도 가능한 에러에 대해 재전송 시도
    - `retries` 속성
  - `send()` 메서드에서 **Exception** 발생시 **Exception** 타입에 따라 `send()` 재호출
  - 콜백 메서드에서 **Exception** 받으면 타입에 따라 `send()` 재호출
- 특별한 이유가 없다면 무한 재시도 X
  - 다음 보내야할 메시지가 밀리는 것임
  - 재시도를 일정시간이나 일정횟수로 제한을 해서 전체적인 메시지가 밀리지 않도록 주의해야함

#### 실패 대응 2 : 기록

- 추후 재처리 위해 기록
  - 별도 파일, DB 등을 이용해서 실패한 메시지 기록
  - 추후에 수동(또는 자동) 보정 작업 진행
- 기록 위치
  - `send()` 메서드에서 **Exception** 발생시
  - `send()` 메서드에 전달한 콜백에서 **Exception** 받는 경우
  - `send()` 메서드가 리턴한 `Future`의 `get()` 메서드에서 **Exception** 발생시

#### 재시도와 메시지 중복 전송 가능성

<img src="assets/producer-retry.png" alt="img" style="zoom:60%;" />

브로커 응답이 늦게 와서 재시도할 경우 중복 발생 가능성이 있다.

enable.idempotence 속성을 이용하여 개선 가능

#### 재시도와 순서

- max.in.flight.requests.per.connection

  - 블로킹없이 한 커넥션에서 전송할 수 있는 최대 전송중인 요청 개수

  - 이 값이 1보다 크면 재시도 시점에 따라 메시지 순서가 바뀔 수 있음 

    - 전송 순서가 중요하면 이 값을 1로 지정

    전송 순서 1 2 3 -> 중간에 1 실패 후 재전송 -> 도착 순서 2 3 1

    

## Consumer

카프카 클러스터에서 메시지를 읽는(consume) 역할을 한다.

컨슈머는 컨슈머 그룹에 속하며 한 개 파티션은 컨슈머 그룹의 한 개 컨슈머에만 연결 가능하다.

즉, 컨슈머 그룹에 속한 컨슈머는 파티션을 공유할 수 없으며 하나의 컨슈머 그룹 내에서는 파티션의 메시지가 순차적으로 처리됨을 보장한다.

<img src="assets/consumer-group.png" alt="img" style="zoom:60%;" />

위 그림을 예로 보면, 컨슈머 0에서 이미 연결했기 때문에 컨슈머 1은 파티션 0과 연결할 수 없다. 컨슈머 2는 파티션 2, 3과 연결된 것처럼 하나의 컨슈머가 여러 파티션과 연결할 수 있다.

크게 세 가지 케이스로 나눌 수 있다.

- 파티션 > 컨슈머

  파티션이 컨슈머 개수보다 많은 경우에는 각 파티션과 컨슈머가 매칭이 되고 컨슈머 중에 하나가 나머지 파티션과 추가적으로 매핑이 될 것이다.

- 파티션 == 컨슈머

  파티션이 컨슈머 개수와 같은 경우는 각 파티션과 컨슈머가 1:1로 매칭이 될 것이다. 가장 이상적인 상황이다.

- 파티션 < 컨슈머

  파티션보다 컨슈머 개수가 많다면 1:1로 매칭이 된 후 남은 컨슈머는 놀게 된다. 이 상황은 피해야 한다.

컨슈머 그룹이 존재하는 이유는 여러 개의 파티션에서 병렬로 데이터를 읽게 되어 빠른 처리가 가능하다는 부분도 있겠지만, 특정 컨슈머에서 문제가 생겼을 때 그룹내 다른 컨슈머가 대신 읽을 수 있도록 리밸런싱되어 장애 상황을 대처할 수 있다는 부분도 있다.

## 성능

- 파티션 파일은 OS 페이지캐시 사용

  - 파티션에 대한 파일 IO를 메모리에서 처리
  - 서버에서 페이지 캐시를 카프카만 사용해야 성능에 유리

- Zero Copy

  - 디스크 버퍼에서 네트워크 버퍼로 직접 데이터 복사

- 컨슈머 추적을 위해 브로커가 하는 일이 비교적 단순

  - 메시지 필터, 메시지 재전송과 같은 일은 브로커가 하지 않음
    - 프로듀서, 컨슈머가 직접 해야 함
  - 브로커는 컨슈머와 파티션 간 매핑 관리

- 묶어서 보내기, 묶어서 받기 (**batch**)

  - 프로듀서: 일정 크기만큼 메시지를 모아서 전송 가능
  - 컨슈머: 최소 크기만큼 메시지를 모아서 조회 가능

  낱개 처리보다 처리량 증가

## 확장성

- 스케일-아웃에 용이한 구조를 가지고 있어서 처리량 증대(확장)가 쉬움
  - 1개 장비의 용량 한계 -> 브로커 추가, 파티션 추가
  - 컨슈머가 느림 -> 컨슈머 추가 (+파티션 추가)

## 리플리카 - 복제

- 리플리카: 파티션의 복제본
  - 복제수(**replication factor**) 만큼 파티션의 복제본이 각 브로커에 생김
- 리더와 팔로워 구성
  - 프로듀서와 컨슈머는 리더를 통해서만 메시지 처리
  - 팔로워는 리더로부터 복제
- 장애 대응
  - 리더가 속한 브로커 장애시 다른 팔로워가 리더가 됨
  - 프로듀서와 컨슈머는 새로운 리더를 통해서 메시지를 다시 처리할 수 있게 됨

## Reference

[kafka 조금 아는 척하기 시리즈](https://www.youtube.com/watch?v=0Ssx7jJJADI&list=PLwouWTPuIjUgr29uSrSkVo8PRmem6HRDE&index=3)

